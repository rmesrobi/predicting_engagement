{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, RidgeCV, LassoCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import (GradientBoostingRegressor, \n",
    "                              RandomForestRegressor,\n",
    "                              AdaBoostRegressor)\n",
    "from sklearn.svm import SVR, SVC\n",
    "import sklearn.model_selection as cv\n",
    "# from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error, log_loss, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import *\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/raffi/Desktop/galvanize/predicting_engagement/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5637, 42), (5636, 5), (5636, 5), (5636, 3), (5636, 3), (5636, 4))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.read_csv('~/Desktop/galvanize/predicting_engagement_v1/notebooks/csv/clean_df.csv')\n",
    "mna_df = pd.read_csv('~/Desktop/galvanize/predicting_engagement_v1/notebooks/csv/mn_aesthetic.csv')\n",
    "mnt_df = pd.read_csv('~/Desktop/galvanize/predicting_engagement_v1/notebooks/csv/mn_technical.csv')\n",
    "x_predict = pd.read_csv('~/Desktop/galvanize/predicting_engagement_v1/notebooks/csv/x_predict.csv')\n",
    "vgg19_predict = pd.read_csv('~/Desktop/galvanize/predicting_engagement_v1/notebooks/csv/vgg19_predict.csv')\n",
    "x_features = pd.read_csv('~/Desktop/galvanize/predicting_engagement_v1/notebooks/csv/x_features.csv')\n",
    "\n",
    "clean_df.shape, mna_df.shape, mnt_df.shape, x_predict.shape, vgg19_predict.shape, x_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['std_aesthetic_x', 'std_aesthetic_y', 'aesthetic_y', 'aesthetic_x'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-54c103392226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m        'x_predict', 'vgg19_predict']\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mexternal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep_external\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mexternal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'number_of_tagged_users'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'tagged_users'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'number_of_caption_words'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'caption_words'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'number_of_caption_hashtags'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'caption_hashtags'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_aesthetic_x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'aesthetic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std_aesthetic_x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'std_aesthetic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_aesthetic_y'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'technical'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std_aesthetic_y'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'std_technical'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1552\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m         )\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['std_aesthetic_x', 'std_aesthetic_y', 'aesthetic_y', 'aesthetic_x'] not in index\""
     ]
    }
   ],
   "source": [
    "save_for_later = ['edge_media_to_parent_comment.count', 'edge_media_preview_comment.count',\n",
    "                 'edge_media_preview_like.count', 'parent_comments_text', 'preview_comments_text',\n",
    "                 'comments_text', 'bag_of_words', 'like_ratio', 'comment_ratio', 'mean_norm_like_ratio', \n",
    "                  'minmax_norm_like_ratio', 'mean_norm_comment_ratio', 'minmax_norm_comment_ratio',\n",
    "                 'image_may_contain', 'username_free_caption', 'comment_hashtags', 'bow',\n",
    "                 'image_label_and_caption', 'engagement_label']\n",
    "keep_columns = ['owner.username', 'shortcode', 'datetime', '__typename','owner.edge_owner_to_timeline_media.count', 'owner.edge_followed_by.count',\n",
    "                'tagged_users', 'caption', 'community_louvain', 'community_raffi', 'like_ratio', 'comment_ratio',\n",
    "                'year', 'month', 'day_of_week', 'hour', 'caption_hashtags', 'edge_media_to_parent_comment.count', \n",
    "               'edge_media_preview_like.count', 'engagement_ratio', 'engagement_label']\n",
    "df = clean_df[keep_columns].copy()\n",
    "df = pd.get_dummies(df, columns = ['__typename'], prefix = ['type'], drop_first= True)\n",
    "df.rename(columns = {'owner.edge_owner_to_timeline_media.count': 'posts', 'owner.edge_followed_by.count': 'followed_by',\n",
    "                    'edge_media_to_parent_comment.count': 'comment_count', 'edge_media_preview_like.count': 'like_count',\n",
    "                    'owner.username': 'username', 'community_louvain': 'louvain', 'community_raffi': 'raffi'}, inplace = True)\n",
    "mna_df.rename(columns = {'shortcodes': 'shortcode'}, inplace = True)\n",
    "mnt_df.rename(columns = {'shortcodes': 'shortcode'}, inplace = True)\n",
    "df = pd.get_dummies(df, columns = ['louvain'], prefix = ['l_'], drop_first= True)\n",
    "df = pd.get_dummies(df, columns = ['raffi'], prefix = ['r_'], drop_first= True)\n",
    "df.fillna('', inplace = True)\n",
    "\n",
    "#new columns\n",
    "df['date'] = df['datetime'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df['number_of_tagged_users'] = df.tagged_users.str.split().apply(len)\n",
    "df['number_of_caption_words'] = df.caption.str.split().apply(len)\n",
    "df['number_of_caption_hashtags'] = df.caption_hashtags.str.split().apply(len)\n",
    "df.sort_values(by = 'date', ascending = False, inplace = True)\n",
    "df['days_since_last_post'] = df.groupby('username')['date'].diff().apply(lambda x: -x.days)\n",
    "df = pd.merge(df, mna_df, how = 'left', on = 'shortcode')\n",
    "df = pd.merge(df, mnt_df, how = 'left', on = 'shortcode')\n",
    "df = pd.merge(df, x_predict, how = 'left', on = 'shortcode')\n",
    "df = pd.merge(df, x_features, how = 'left', on = 'shortcode')\n",
    "df['predictions'] = df['predictions'].apply(lambda x: str(x)[2:-2])\n",
    "df['x_predict'] = pd.to_numeric(df['predictions'])\n",
    "df = pd.merge(df, vgg19_predict, how = 'left', on = 'shortcode')\n",
    "df['predictions_y'] = df['predictions_y'].apply(lambda x: str(x)[2:-2])\n",
    "df['vgg19_predict'] = pd.to_numeric(df['predictions_y'])\n",
    "df['new_engagement'] = df['like_ratio'] + df['comment_ratio']\n",
    "\n",
    "\n",
    "df.fillna(0, inplace = True)\n",
    "\n",
    "keep_external = ['datetime', 'posts', 'followed_by','year',\n",
    "       'month', 'day_of_week', 'hour','comment_count',\n",
    "       'like_count', 'engagement_ratio',\n",
    "       'type_GraphSidecar', 'type_GraphVideo', 'l__1', 'l__2', 'l__3', 'l__4',\n",
    "       'l__5', 'l__6', 'l__7',\n",
    "       'number_of_tagged_users', 'number_of_caption_words',\n",
    "       'number_of_caption_hashtags', 'days_since_last_post',\n",
    "       'aesthetic_x', 'std_aesthetic_x',\n",
    "       'aesthetic_y', 'std_aesthetic_y',\n",
    "       'x_predict', 'vgg19_predict']\n",
    "\n",
    "external_df = df[keep_external].copy()\n",
    "external_df.rename(columns = {'number_of_tagged_users': 'tagged_users', 'number_of_caption_words': 'caption_words', 'number_of_caption_hashtags': 'caption_hashtags', 'mean_aesthetic_x': 'aesthetic', 'std_aesthetic_x': 'std_aesthetic', 'mean_aesthetic_y': 'technical', 'std_aesthetic_y': 'std_technical'}, inplace = True)\n",
    "\n",
    "external_df.to_csv('~/Desktop/galvanize/capstone_3/external_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/Desktop/galvanize/capstone_3/new_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = external_df.select_dtypes(include = np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['posts', 'followed_by', 'year', 'month', 'day_of_week', 'hour',\n",
       "       'comment_count', 'like_count', 'engagement_ratio', 'type_GraphSidecar',\n",
       "       'type_GraphVideo', 'l__1', 'l__2', 'l__3', 'l__4', 'l__5', 'l__6',\n",
       "       'l__7', 'tagged_users', 'caption_words', 'caption_hashtags',\n",
       "       'days_since_last_post', 'aesthetic', 'std_aesthetic', 'technical',\n",
       "       'std_technical', 'x_predict', 'vgg19_predict'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['posts', 'followed_by', 'year', 'month', 'day_of_week', 'hour',\n",
       "       'comment_count', 'engagement_ratio', 'type_GraphSidecar',\n",
       "       'type_GraphVideo', 'l__1', 'l__2', 'l__3', 'l__4', 'l__5', 'l__6',\n",
       "       'l__7', 'tagged_users', 'caption_words', 'caption_hashtags',\n",
       "       'days_since_last_post', 'aesthetic', 'std_aesthetic', 'technical',\n",
       "       'std_technical', 'x_predict', 'vgg19_predict'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric.columns.drop('like_count', 'comment_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(n_estimators = 2000, n_jobs = -1)\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "models = [lr, rf, knn]\n",
    "model_names = ['lr', 'rf', 'knn']\n",
    "\n",
    "X_columns = ['posts', 'followed_by', 'year', 'month', 'day_of_week', 'hour','type_GraphSidecar',\n",
    "             'type_GraphVideo', 'l__1', 'l__2', 'l__3', 'l__4', 'l__5', 'l__6', 'l__7',\n",
    "             'tagged_users', 'caption_words', 'caption_hashtags','days_since_last_post', \n",
    "             'aesthetic', 'std_aesthetic', 'technical','std_technical', 'x_predict', 'vgg19_predict']\n",
    "\n",
    "def get_train_test_split(df):\n",
    "    \"\"\"Get numerical columns from df, return X and y\"\"\"\n",
    "\n",
    "    X = df_numeric[X_columns]\n",
    "    Y = df_numeric['engagement_ratio']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def run_model(models, X_train, X_test, y_train, y_test):\n",
    "    for model, model_name in zip(models, model_names):\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, yhat)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        r2 = r2_score(y_test, yhat)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f'{model_name} r2: {r2}, mae: {mae}, mse: {mse}, rmse: {rmse}')\n",
    "        \n",
    "    A = df_numeric[X_columns]\n",
    "    b = df_numeric['engagement_ratio']\n",
    "    A = np.column_stack([np.ones(A.shape[0]), A])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(A, b, test_size=0.20, random_state=42)\n",
    "    # calculate the economy SVD for the data matrix A\n",
    "    U,S,Vt = np.linalg.svd(X_train, full_matrices=False)\n",
    "    # solve Ax = b for the best possible approximate solution in terms of least squares\n",
    "    x_hat = Vt.T @ np.linalg.inv(np.diag(S)) @ U.T @ y_train\n",
    "    # perform train and test inference\n",
    "    y_pred = X_train @ x_hat\n",
    "    yhat = X_test @ x_hat\n",
    "    mse = mean_squared_error(y_test, yhat)\n",
    "    mae = mean_absolute_error(y_test, yhat)\n",
    "    r2 = r2_score(y_test, yhat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'svd r2: {r2}, mae: {mae}, mse: {mse}, rmse: {rmse}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr r2: 0.1035265093193779, mae: 1.2125862476632085, mse: 3.1834786617177406, rmse: 1.7842305517274781\n",
      "rf r2: 0.4350189648379781, mae: 0.9702803588759809, mse: 2.006311495444174, rmse: 1.4164432552856376\n",
      "knn r2: 0.29667926016388624, mae: 1.0333765000231783, mse: 2.49757141832705, rmse: 1.5803706585250974\n",
      "svd r2: 0.10352650998370971, mae: 1.2125862466816244, mse: 3.1834786593586237, rmse: 1.784230551066376\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_split(df)\n",
    "run_model(models, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_numeric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dbc881474d1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_numeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiverging_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m230\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_cmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.7, center=0,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_numeric' is not defined"
     ]
    }
   ],
   "source": [
    "corr = df_numeric.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.7, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
