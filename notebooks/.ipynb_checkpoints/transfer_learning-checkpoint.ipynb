{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.applications import Xception\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Input\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_df = pd.read_csv('~/Desktop/galvanize/predicting_engagement_v1/notebooks/csv/external_df.csv')\n",
    "clean_df = pd.read_csv('~/Desktop/galvanize/predicting_engagement_v1/notebooks/csv/clean_df.csv')\n",
    "external_df.drop(columns = ['Unnamed: 0', 'datetime'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#holdout\n",
    "r_df = df.copy()\n",
    "holdout = 0.2\n",
    "mask = np.random.rand(len(df)) < (1-holdout)\n",
    "train_val_df = r_df[mask]\n",
    "test_df = r_df[~mask]\n",
    "\n",
    "X = df.copy()\n",
    "Y = df['new_engagement']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = .2, random_state = seed, shuffle = True)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check classes\n",
    "class_names_int = list(X_train['engagement_label'].unique())\n",
    "class_names_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image folder paths - MAKE SURE SHUTIL IS SET TO COPY AND NOT MOVE\n",
    "\n",
    "train_images = '/home/ubuntu/images/regression/train/'\n",
    "val_images = '/home/ubuntu/images/regression/val/'\n",
    "\n",
    "#move image files to categories\n",
    "for c in class_names_int:\n",
    "    for i in list(X_train[X_train['engagement_label'] == c]['shortcode']): #image id\n",
    "        try:\n",
    "            get_image = os.path.join(r'/home/ubuntu/train_/' + str(c), i + '.jpg') #path to images\n",
    "            move_image_to_cat = shutil.copy(get_image, '/home/ubuntu/images/regression/train/')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "for c in class_names_int:\n",
    "    for i in list(X_test[X_test['engagement_label'] == c]['shortcode']): #image id\n",
    "        try:\n",
    "            get_image = os.path.join(r'/home/ubuntu/train_/' + str(c), i + '.jpg') #path to images\n",
    "            move_image_to_cat = shutil.copy(get_image, '/home/ubuntu/images/regression/val/')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "! rm -rf train_val_images/.ipynb_checkpoints/\n",
    "! rm -rf test_images/.ipynb_checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath for flow_from_directory\n",
    "X_train['directory_path'] = '/home/ubuntu/images/regression/train/' + X_train['shortcode'] + '.jpg'\n",
    "X_test['directory_path'] = '/home/ubuntu/images/regression/val/' + X_test['shortcode'] + '.jpg'\n",
    "\n",
    "#create a dataset\n",
    "train_dir = '/home/ubuntu/images/regression/'\n",
    "val_dir = '/home/ubuntu/images/regression/'\n",
    "batch_size = 16\n",
    "img_height = 299\n",
    "img_width = 299\n",
    "\n",
    "trainimggen = ImageDataGenerator(rescale = (1./255),\n",
    "                                  horizontal_flip=True, \n",
    "                                  rotation_range=10, \n",
    "                                  width_shift_range=1, \n",
    "                                  height_shift_range=1,\n",
    "                                  brightness_range=None,\n",
    "                                  shear_range=1,\n",
    "                                  zoom_range=1,\n",
    "                                  channel_shift_range=2)\n",
    "validationimggen = ImageDataGenerator(rescale = (1./255))\n",
    "\n",
    "\n",
    "train_ds = trainimggen.flow_from_dataframe(dataframe = X_train,\n",
    "                                           x_col = 'directory_path',\n",
    "                                           y_col = 'new_engagement',\n",
    "                                           class_mode = 'raw',\n",
    "                                           target_size=(img_height,img_width), \n",
    "                                           batch_size=batch_size)\n",
    "\n",
    "val_ds = validationimggen.flow_from_dataframe(dataframe = X_test,\n",
    "                                           x_col = 'directory_path',\n",
    "                                           y_col = 'new_engagement',\n",
    "                                           class_mode = 'raw',\n",
    "                                           target_size=(img_height,img_width), \n",
    "                                           batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables for batch size epoch step\n",
    "ti = 4508\n",
    "vi = 1128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model helper functions\n",
    "num_classes = 1\n",
    "\n",
    "def add_new_last_layer(base_model, nb_classes= num_classes):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "    Args:\n",
    "    base_model: keras model excluding top\n",
    "    nb_classes: # of classes\n",
    "    Returns:\n",
    "    new keras model with last layer\n",
    "    \"\"\"\n",
    "    # Get the output shape of the models last layer\n",
    "    x = base_model.output\n",
    "    # Convert final MxNxC tensor output into a 1xC tensor where C is the # of channels.\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dense(1024, activation='relu')(x) \n",
    "    x = keras.layers.Dropout(.5)(x)\n",
    "    predictions = keras.layers.Dense(1, activation = 'linear')(x)\n",
    "    model = keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "# This will freeze the weights on all the layers except for our new dense layer\n",
    "def setup_to_transfer_learn(model, base_model):\n",
    "    \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.01),\n",
    "              loss=['mean_absolute_percentage_error'],\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "def change_trainable_layers(model, trainable_index):\n",
    "    for layer in model.layers[:trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[trainable_index:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "project_name = \"transfer_learning\"\n",
    "tensorboard_cb = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load vgg19 as base model\n",
    "vgg19 = keras.applications.VGG19(include_top=False, \n",
    "                                      weights='imagenet', input_shape=(img_height,img_width,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model = add_new_last_layer(vgg19)\n",
    "setup_to_transfer_learn(vgg19_model,vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run last layer\n",
    "training_images = ti\n",
    "steps_p_epoch = training_images / batch_size\n",
    "validation_images = vi\n",
    "validation_steps = validation_images / batch_size\n",
    "\n",
    "vgg19_model.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.01),\n",
    "              loss=['mean_squared_error'],\n",
    "              metrics=['mae'])\n",
    "\n",
    "model_cp= ModelCheckpoint(filepath='/home/ubuntu/models/vgg19_model.hdf5',\n",
    "                            save_best_only=True)\n",
    "\n",
    "vgg19_model_history = vgg19_model.fit(train_ds, \n",
    "                validation_data=val_ds,\n",
    "                epochs=10,\n",
    "                callbacks=[model_cp, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize training results\n",
    "\n",
    "mse = vgg19_model_history.history['mse']\n",
    "val_mse = vgg19_model_history.history['val_mse']\n",
    "loss = vgg19_model_history.history['loss']\n",
    "val_loss = vgg19_model_history.history['val_loss']\n",
    "\n",
    "epochs_range = range(10)\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range, mse, label = 'Training Accuracy')\n",
    "plt.plot(epochs_range, val_mse, label = 'Validation Accuracy')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.autoscale()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range, loss, label = 'Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label = 'Validation Loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.autoscale()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming that we are unfreezing block5_pool - 2M params\n",
    "change_trainable_layers(vgg19_model, 20)\n",
    "# vgg19_model.summary()\n",
    "# for i, layer in enumerate(vgg19_model.layers):\n",
    "#     print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run last layer\n",
    "training_images = ti\n",
    "steps_p_epoch = training_images / batch_size\n",
    "validation_images = vi\n",
    "validation_steps = validation_images / batch_size\n",
    "\n",
    "vgg19_model.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.001),\n",
    "              loss=['mean_squared_error'],\n",
    "              metrics=['mae'])\n",
    "\n",
    "model_cp= ModelCheckpoint(filepath='/home/ubuntu/models/vgg19_model.hdf5',\n",
    "                            save_best_only=True)\n",
    "\n",
    "vgg19_model_2_history = vgg19_model.fit(train_ds, \n",
    "                validation_data=val_ds,\n",
    "                epochs=20,\n",
    "                callbacks=[model_cp, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xception model\n",
    "xception = keras.applications.Xception(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(img_height,img_width,3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_model = add_new_last_layer(xception)\n",
    "setup_to_transfer_learn(x_model,xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run last layer\n",
    "training_images = ti\n",
    "steps_p_epoch = training_images / batch_size\n",
    "validation_images = vi\n",
    "validation_steps = validation_images / batch_size\n",
    "\n",
    "x_model.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.01),\n",
    "              loss=['mean_absolute_percentage_error'],\n",
    "              metrics=['mse'])\n",
    "\n",
    "model_cp= ModelCheckpoint(filepath='/home/ubuntu/models/x_model.hdf5',\n",
    "                            save_best_only=True)\n",
    "\n",
    "x_model_history = vgg19_model.fit(train_ds, \n",
    "                validation_data=val_ds,\n",
    "                epochs=10,\n",
    "                callbacks=[model_cp, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_trainable_layers(x_model, 129)\n",
    "# x_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run last layer\n",
    "training_images = ti\n",
    "steps_p_epoch = training_images / batch_size\n",
    "validation_images = vi\n",
    "validation_steps = validation_images / batch_size\n",
    "\n",
    "x_model.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.001),\n",
    "              loss=['mean_absolute_percentage_error'],\n",
    "              metrics= ['mse'])\n",
    "\n",
    "model_cp= ModelCheckpoint(filepath='/home/ubuntu/models/x_model.hdf5',\n",
    "                            save_best_only=True)\n",
    "\n",
    "x_model_2_history = x_model.fit(train_ds, \n",
    "                validation_data=val_ds,\n",
    "                epochs=20,\n",
    "                callbacks=[model_cp, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize training results\n",
    "\n",
    "mse = x_model_2_history.history['mse']\n",
    "val_mse = x_model_2_history.history['val_mse']\n",
    "mape = x_model_2_history.history['loss']\n",
    "val_mape = x_model_2_history.history['val_loss']\n",
    "\n",
    "epochs_range = range(20)\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range, mse, label = 'Training MSE')\n",
    "plt.plot(epochs_range, val_mse, label = 'Validation MSE')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.autoscale()\n",
    "plt.title('Training and Validation MSE')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range, mape, label = 'Training Loss (MAPE)')\n",
    "plt.plot(epochs_range, val_mape, label = 'Validation Loss (MAPE)')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.autoscale()\n",
    "plt.savefig('/home/ubuntu/graphs/xception_train_val_mse_mape.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean score for AVA dataset\n",
    "def mean_score(scores):\n",
    "    si = np.arange(1, 11, 1)\n",
    "    mean = np.sum(scores * si)\n",
    "    return mean\n",
    "\n",
    "# calculate standard deviation of scores for AVA dataset\n",
    "def std_score(scores):\n",
    "    si = np.arange(1, 11, 1)\n",
    "    mean = mean_score(scores)\n",
    "    std = np.sqrt(np.sum(((si - mean) ** 2) * scores))\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobilenet\n",
    "base_model = MobileNet((img_height, img_width, 3), alpha = 1, include_top=False, pooling= 'avg')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = layers.Dropout(0.75)(base_model.output)\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "mna_model = Model(base_model.input, x)\n",
    "mna_model.load_weights('/home/ubuntu/weights/weights_mobilenet_aesthetic_0.07.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def earth_mover_loss(y_true, y_pred):\n",
    "    cdf_ytrue = K.cumsum(y_true, axis=-1)\n",
    "    cdf_ypred = K.cumsum(y_pred, axis=-1)\n",
    "    samplewise_emd = K.sqrt(K.mean(K.square(K.abs(cdf_ytrue - cdf_ypred)), axis=-1))\n",
    "    return K.mean(samplewise_emd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run last layer\n",
    "training_images = ti\n",
    "steps_p_epoch = training_images / batch_size\n",
    "validation_images = vi\n",
    "validation_steps = validation_images / batch_size\n",
    "\n",
    "mna_model.compile(optimizer= keras.optimizers.Adam(learning_rate = 0.001),\n",
    "              loss=earth_mover_loss,\n",
    "              metrics= ['mse'])\n",
    "\n",
    "model_cp= ModelCheckpoint(filepath='/home/ubuntu/models/mna_model.hdf5',\n",
    "                            save_best_only=True)\n",
    "\n",
    "mna_model_history = mna_model.fit(train_ds, \n",
    "                validation_data=val_ds,\n",
    "                epochs=20,\n",
    "                callbacks=[model_cp, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load image for predictions\n",
    "fp = train_ds.filepaths[850]\n",
    "img = tf.keras.preprocessing.image.load_img(fp, (299,299))\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=tf.keras.preprocessing.image.load_img(fp,target_size=(299,299))\n",
    "img=tf.keras.preprocessing.image.img_to_array(img)\n",
    "predictions=mn_model_aesthetic.predict(np.array([img]))\n",
    "scores = mn_model_aesthetic.predict(np.array([img]), verbose=0)[0]\n",
    "mean_score(scores), std_score(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating predictions - save in pandas dataframe\n",
    "tfp = train_ds.filepaths\n",
    "vfp = val_ds.filepaths\n",
    "\n",
    "mn_aesthetic = pd.DataFrame()\n",
    "scores_list = []\n",
    "shortcodes = []\n",
    "std_list = []\n",
    "filepath = []\n",
    "\n",
    "#loop over training\n",
    "for fp in tfp:\n",
    "    img=tf.keras.preprocessing.image.load_img(fp,target_size=(299,299))\n",
    "    img=tf.keras.preprocessing.image.img_to_array(img)\n",
    "    scores = mna_model.predict(np.array([img]), verbose=0)[0]\n",
    "    mean = mean_score(scores)\n",
    "    std = std_score(scores)\n",
    "    shortcode = fp.split('/')[-1][:-4]\n",
    "    scores_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    shortcodes.append(shortcode)\n",
    "    fp = '/home/ubuntu/images/regression/train/' + shortcode + '.jpg'\n",
    "    filepath.append(fp)\n",
    "\n",
    "#loop over val\n",
    "for fp in vfp:\n",
    "    img=tf.keras.preprocessing.image.load_img(fp,target_size=(299,299))\n",
    "    img=tf.keras.preprocessing.image.img_to_array(img)\n",
    "    scores = mna_model.predict(np.array([img]), verbose=0)[0]\n",
    "    mean = mean_score(scores)\n",
    "    std = std_score(scores)\n",
    "    shortcode = fp.split('/')[-1][:-4]\n",
    "    scores_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    shortcodes.append(shortcode)\n",
    "    fp = '/home/ubuntu/images/regression/val/' + shortcode + '.jpg'\n",
    "    filepath.append(fp)\n",
    "    \n",
    "mn_aesthetic['shortcodes'] = shortcodes\n",
    "mn_aesthetic['mean_aesthetic'] = scores_list\n",
    "mn_aesthetic['std_aesthetic'] = std_list\n",
    "mn_aesthetic['filepath'] = filepath\n",
    "\n",
    "mn_aesthetic.to_csv('/home/ubuntu/csv/mn_aesthetic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobilenet\n",
    "mobilenet_model = MobileNet((None, None, 3), alpha=1, include_top=False, pooling='avg', weights=None)\n",
    "x = layers.Dropout(0.75)(mobilenet_model.output)\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "mn_model_technical = Model(mobilenet_model.input, x)\n",
    "mn_model_technical.load_weights('/home/ubuntu/weights/weights_mobilenet_technical_0.11.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating predictions\n",
    "tfp = train_ds.filepaths\n",
    "vfp = val_ds.filepaths\n",
    "\n",
    "mn_technical = pd.DataFrame()\n",
    "scores_list = []\n",
    "shortcodes = []\n",
    "std_list = []\n",
    "filepath = []\n",
    "\n",
    "#loop over training\n",
    "for fp in tfp:\n",
    "    img=tf.keras.preprocessing.image.load_img(fp,target_size=(299,299))\n",
    "    img=tf.keras.preprocessing.image.img_to_array(img)\n",
    "    scores = mn_model_technical.predict(np.array([img]), verbose=0)[0]\n",
    "    mean = mean_score(scores)\n",
    "    std = std_score(scores)\n",
    "    shortcode = fp.split('/')[-1][:-4]\n",
    "    scores_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    shortcodes.append(shortcode)\n",
    "    fp = '/home/ubuntu/images/regression/val/' + shortcode + '.jpg'\n",
    "    filepath.append(fp)\n",
    "\n",
    "#loop over val\n",
    "for fp in vfp:\n",
    "    img=tf.keras.preprocessing.image.load_img(fp,target_size=(299,299))\n",
    "    img=tf.keras.preprocessing.image.img_to_array(img)\n",
    "    scores = mn_model_technical.predict(np.array([img]), verbose=0)[0]\n",
    "    mean = mean_score(scores)\n",
    "    std = std_score(scores)\n",
    "    shortcode = fp.split('/')[-1][:-4]\n",
    "    scores_list.append(mean)\n",
    "    std_list.append(std)\n",
    "    shortcodes.append(shortcode)\n",
    "    fp = '/home/ubuntu/images/regression/val/' + shortcode + '.jpg'\n",
    "    filepath.append(fp)\n",
    "\n",
    "mn_technical['shortcodes'] = shortcodes\n",
    "mn_technical['mean_aesthetic'] = scores_list\n",
    "mn_technical['std_aesthetic'] = std_list\n",
    "mn_technical['filepath'] = filepath\n",
    "\n",
    "mn_technical.to_csv('/home/ubuntu/csv/mn_technical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_technical.rename(columns = {'mean_aesthetic': 'mean_technical', 'std_aesthetic': 'std_technical'}, inplace = True)\n",
    "mn_technical.sort_values(by = 'mean_technical', ascending = False, inplace = True)\n",
    "mn_technical.to_csv('/home/ubuntu/csv/mn_technical.csv')\n",
    "mn_aesthetic.sort_values(by = 'mean_aesthetic', ascending = False, inplace = True)\n",
    "mn_aesthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xception model for feature extraction\n",
    "x_obj_model = keras.applications.Xception(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(299, 299, 3),\n",
    "    include_top=True)  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating predictions\n",
    "tfp = train_ds.filepaths\n",
    "vfp = val_ds.filepaths\n",
    "top = 3\n",
    "x_features = pd.DataFrame()\n",
    "\n",
    "shortcodes = []\n",
    "keys = []\n",
    "values = []\n",
    "\n",
    "#loop over training\n",
    "for fp in tfp:\n",
    "    img=tf.keras.preprocessing.image.load_img(fp,target_size=(299,299))\n",
    "    img=tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img=tf.keras.applications.xception.preprocess_input(img)\n",
    "    predictions=x_obj_model.predict(np.array([img]))\n",
    "    decode = decode_predictions(predictions,top= top)\n",
    "    shortcode = fp.split('/')[-1][:-4]\n",
    "    shortcodes.append(shortcode)\n",
    "    tkeys = []\n",
    "    tvalues = []\n",
    "    for d in decode[0]:\n",
    "        key = d[1]\n",
    "        tkeys.append(key)\n",
    "        value = d[2]\n",
    "        tvalues.append(value)\n",
    "    keys.append(tkeys)\n",
    "    values.append(tvalues)\n",
    "\n",
    "for fp in vfp:\n",
    "    img=tf.keras.preprocessing.image.load_img(fp,target_size=(299,299))\n",
    "    img=tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img=tf.keras.applications.xception.preprocess_input(img)\n",
    "    predictions=x_obj_model.predict(np.array([img]))\n",
    "    decode = decode_predictions(predictions,top= top)\n",
    "    shortcode = fp.split('/')[-1][:-4]\n",
    "    shortcodes.append(shortcode)\n",
    "    vkeys = []\n",
    "    vvalues = []\n",
    "    for d in decode[0]:\n",
    "        key = d[1]\n",
    "        vkeys.append(key)\n",
    "        value = d[2]\n",
    "        vvalues.append(value)\n",
    "    keys.append(vkeys)\n",
    "    values.append(vvalues)\n",
    "\n",
    "x_features['shortcode'] = shortcodes\n",
    "x_features['keys'] = keys\n",
    "x_features['values'] = values\n",
    "\n",
    "x_features.to_csv('/home/ubuntu/csv/x_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating predictions - save Xception predictions into pandas dataframe\n",
    "tfp = train_ds.filepaths\n",
    "vfp = val_ds.filepaths\n",
    "x_predict = pd.DataFrame()\n",
    "\n",
    "shortcodes = []\n",
    "predictions = []\n",
    "\n",
    "#loop over training\n",
    "for fp in tfp:\n",
    "    img=tf.keras.preprocessing.image.load_img(fp,target_size=(299,299))\n",
    "    img=tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img=tf.keras.applications.xception.preprocess_input(img)\n",
    "    predictions.append(x_model_3.predict(np.array([img])))\n",
    "    shortcode = fp.split('/')[-1][:-4]\n",
    "    shortcodes.append(shortcode)\n",
    "\n",
    "for fp in vfp:\n",
    "    img=tf.keras.preprocessing.image.load_img(fp,target_size=(299,299))\n",
    "    img=tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img=tf.keras.applications.xception.preprocess_input(img)\n",
    "    predictions.append(x_model_3.predict(np.array([img])))\n",
    "    shortcode = fp.split('/')[-1][:-4]\n",
    "    shortcodes.append(shortcode)\n",
    "\n",
    "x_predict['shortcode'] = shortcodes\n",
    "x_predict['predictions'] = predictions\n",
    "\n",
    "x_predict.to_csv('/home/ubuntu/csv/x_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_model = load_model('/home/ubuntu/models/vgg19_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating predictions - save predictions for vgg19 into pandas dataframe\n",
    "tfp = train_ds.filepaths\n",
    "vfp = val_ds.filepaths\n",
    "vgg19_predict = pd.DataFrame()\n",
    "\n",
    "shortcodes = []\n",
    "predictions = []\n",
    "\n",
    "#loop over training\n",
    "for fp in tfp:\n",
    "    img=tf.keras.preprocessing.image.load_img(fp,target_size=(299,299))\n",
    "    img=tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img=tf.keras.applications.xception.preprocess_input(img)\n",
    "    predictions.append(x_model_3.predict(np.array([img])))\n",
    "    shortcode = fp.split('/')[-1][:-4]\n",
    "    shortcodes.append(shortcode)\n",
    "\n",
    "for fp in vfp:\n",
    "    img=tf.keras.preprocessing.image.load_img(fp,target_size=(299,299))\n",
    "    img=tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img=tf.keras.applications.xception.preprocess_input(img)\n",
    "    predictions.append(x_model_3.predict(np.array([img])))\n",
    "    shortcode = fp.split('/')[-1][:-4]\n",
    "    shortcodes.append(shortcode)\n",
    "\n",
    "vgg19_predict['shortcode'] = shortcodes\n",
    "vgg19_predict['predictions'] = predictions\n",
    "\n",
    "vgg19_predict.to_csv('/home/ubuntu/csv/vgg19_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for image classification - src not available in this file\n",
    "pred = x_train_model.predict(val_ds).argmax(axis = 1)\n",
    "y_true = val_ds.labels\n",
    "#confusion matrix for classification\n",
    "mat = confusion_matrix(y_true, pred)\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "sns.heatmap(mat.T, square = True, annot = True, fmt = 'd', cbar = False)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['class 0', 'class 1', 'class 2', 'class 3']\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('model', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(lowercase=True, tokenizer=None, stop_words='english',\n",
    "                             analyzer='word', max_df=1.0, min_df=1,\n",
    "                             max_features=None, ngram_range = (1,2))\n",
    "\n",
    "count_vect.fit(X_train, y_train)\n",
    "\n",
    "target_names = target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts = count_vect.transform(X_train)\n",
    "print(\"The type of X_train_counts is {0}.\".format(type(X_train_counts)))\n",
    "print(\"The X matrix has {0} rows (documents) and {1} columns (words).\".format(\n",
    "        X_train_counts.shape[0], X_train_counts.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer(use_idf=True)\n",
    "tfidf_transformer.fit(X_train_counts)\n",
    "X_train_tfidf = tfidf_transformer.transform(X_train_counts)\n",
    "\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "tfidf_transformer.fit(X_test_counts)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "nb_model.fit(X_train_tfidf, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "sns.heatmap(mat.T, square = True, annot = True, fmt = 'd', cbar = False)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_words = count_vect.get_feature_names()\n",
    "n = 10 #number of top words associated with the category that we wish to see\n",
    "\n",
    "for cat in range(4):    \n",
    "    print(f\"\\nTarget: {cat}, name: {target_names[cat]}\")\n",
    "    log_prob = nb_model.feature_log_prob_[cat]\n",
    "    i_topn = np.argsort(log_prob)[::-1][:n]\n",
    "    features_topn = [feature_words[i] for i in i_topn]\n",
    "    print(f\"Top {n} tokens: \", features_topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
